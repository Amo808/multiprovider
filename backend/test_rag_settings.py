"""
RAG Settings Tester
–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ RAG

–¢–µ—Å—Ç–∏—Ä—É–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:
- chunk_mode: "fixed", "percent", "adaptive"
- chunk_percent: 10%, 50%, 100%
- min_similarity: 0.1, 0.3, 0.5
- keyword_weight / semantic_weight: —Ä–∞–∑–Ω—ã–µ –±–∞–ª–∞–Ω—Å—ã
- use_rerank: True/False
"""

import asyncio
import httpx
import json
import time
from typing import Dict, Any, List
from datetime import datetime

API_URL = "http://localhost:8000"

# –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤
TEST_QUERIES = [
    # –ü–æ–∏—Å–∫ –¥–∞–Ω–Ω—ã—Ö
    {"query": "—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω —É—á–∞—Å—Ç–≤–æ–≤–∞–ª–æ", "type": "find_data"},
    {"query": "–∫–∞–∫–∏–µ —á–∏—Å–ª–∞ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è", "type": "find_data"},
    # –ü–æ–ª–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
    {"query": "–æ —á–µ–º —ç—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç", "type": "full_document"},
    {"query": "–∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ", "type": "summarize"},
    # –ü–æ–∏—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏  
    {"query": "—á—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç—Å—è –æ –†–æ—Å—Å–∏–∏", "type": "search"},
    {"query": "–æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞", "type": "analyze"},
]

# –ö–æ–º–±–∏–Ω–∞—Ü–∏–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
TEST_CONFIGS = [
    # –ë–∞–∑–æ–≤—ã–µ —Ä–µ–∂–∏–º—ã
    {
        "name": "Fixed 10 chunks",
        "chunk_mode": "fixed",
        "max_chunks": 10,
        "chunk_percent": 20,
        "min_similarity": 0.3,
        "keyword_weight": 0.3,
        "semantic_weight": 0.7,
        "use_rerank": True,
    },
    {
        "name": "Fixed 50 chunks",
        "chunk_mode": "fixed",
        "max_chunks": 50,
        "chunk_percent": 20,
        "min_similarity": 0.3,
        "keyword_weight": 0.3,
        "semantic_weight": 0.7,
        "use_rerank": True,
    },
    {
        "name": "Percent 20%",
        "chunk_mode": "percent",
        "max_chunks": 50,
        "chunk_percent": 20,
        "min_similarity": 0.3,
        "keyword_weight": 0.3,
        "semantic_weight": 0.7,
        "use_rerank": True,
    },
    {
        "name": "Percent 50%",
        "chunk_mode": "percent",
        "max_chunks": 100,
        "chunk_percent": 50,
        "min_similarity": 0.3,
        "keyword_weight": 0.3,
        "semantic_weight": 0.7,
        "use_rerank": True,
    },
    {
        "name": "Percent 100% (full doc)",
        "chunk_mode": "percent",
        "max_chunks": 500,
        "chunk_percent": 100,
        "min_similarity": 0.1,
        "keyword_weight": 0.3,
        "semantic_weight": 0.7,
        "use_rerank": False,
    },
    {
        "name": "Adaptive (AI decides)",
        "chunk_mode": "adaptive",
        "max_chunks": 50,
        "chunk_percent": 20,
        "min_similarity": 0.3,
        "keyword_weight": 0.3,
        "semantic_weight": 0.7,
        "use_rerank": True,
        "adaptive_chunks": True,
    },
    # –†–∞–∑–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    {
        "name": "Low threshold (0.1)",
        "chunk_mode": "fixed",
        "max_chunks": 30,
        "chunk_percent": 20,
        "min_similarity": 0.1,
        "keyword_weight": 0.3,
        "semantic_weight": 0.7,
        "use_rerank": True,
    },
    {
        "name": "High threshold (0.5)",
        "chunk_mode": "fixed",
        "max_chunks": 30,
        "chunk_percent": 20,
        "min_similarity": 0.5,
        "keyword_weight": 0.3,
        "semantic_weight": 0.7,
        "use_rerank": True,
    },
    # –†–∞–∑–Ω—ã–µ –±–∞–ª–∞–Ω—Å—ã –ø–æ–∏—Å–∫–∞
    {
        "name": "Keywords heavy (70/30)",
        "chunk_mode": "fixed",
        "max_chunks": 30,
        "chunk_percent": 20,
        "min_similarity": 0.3,
        "keyword_weight": 0.7,
        "semantic_weight": 0.3,
        "use_rerank": True,
    },
    {
        "name": "Semantic heavy (10/90)",
        "chunk_mode": "fixed",
        "max_chunks": 30,
        "chunk_percent": 20,
        "min_similarity": 0.3,
        "keyword_weight": 0.1,
        "semantic_weight": 0.9,
        "use_rerank": True,
    },
    # –°/–±–µ–∑ rerank
    {
        "name": "No rerank",
        "chunk_mode": "fixed",
        "max_chunks": 30,
        "chunk_percent": 20,
        "min_similarity": 0.3,
        "keyword_weight": 0.3,
        "semantic_weight": 0.7,
        "use_rerank": False,
    },
]


async def get_documents() -> List[Dict]:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    async with httpx.AsyncClient() as client:
        resp = await client.get(f"{API_URL}/api/rag/documents")
        if resp.status_code == 200:
            return resp.json().get("documents", [])
        return []


async def test_rag_query(
    query: str,
    config: Dict[str, Any],
    document_id: str = None
) -> Dict[str, Any]:
    """–í—ã–ø–æ–ª–Ω–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ RAG"""
    
    request_body = {
        "message": query,  # –û–¥–Ω–æ –ø–æ–ª–µ message, –Ω–µ –º–∞—Å—Å–∏–≤ messages
        "model": "gpt-4o-mini",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—à—ë–≤—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–æ–≤
        "provider": "openai",
        "stream": False,  # –û—Ç–∫–ª—é—á–∞–µ–º streaming –¥–ª—è —Ç–µ—Å—Ç–æ–≤
        "rag": {
            "enabled": True,
            "document_id": document_id,
            "chunk_mode": config.get("chunk_mode", "fixed"),
            "max_chunks": config.get("max_chunks", 50),
            "chunk_percent": config.get("chunk_percent", 20),
            "min_similarity": config.get("min_similarity", 0.3),
            "keyword_weight": config.get("keyword_weight", 0.3),
            "semantic_weight": config.get("semantic_weight", 0.7),
            "use_rerank": config.get("use_rerank", True),
            "adaptive_chunks": config.get("adaptive_chunks", False),
            "include_metadata": True,
        }
    }
    
    start_time = time.time()
    
    async with httpx.AsyncClient(timeout=120.0) as client:
        try:
            resp = await client.post(
                f"{API_URL}/api/chat/send",
                json=request_body,
                headers={"Content-Type": "application/json"}
            )
            
            elapsed = time.time() - start_time
            
            if resp.status_code == 200:
                # API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç SSE –¥–∞–∂–µ —Å stream=False, –ø–∞—Ä—Å–∏–º –ø–æ—Å—Ç—Ä–æ—á–Ω–æ
                full_response = ""
                sources = []
                rag_debug = {}
                
                for line in resp.text.split("\n"):
                    line = line.strip()
                    if not line or not line.startswith("data:"):
                        continue
                    
                    data_str = line[5:].strip()  # –£–±–∏—Ä–∞–µ–º "data:" –∏ –ø—Ä–æ–±–µ–ª—ã
                    if data_str == "[DONE]":
                        break
                    
                    try:
                        data = json.loads(data_str)
                        msg_type = data.get("type", "")
                        
                        if msg_type == "content":
                            full_response += data.get("content", "")
                        elif msg_type == "rag_sources":
                            sources = data.get("sources", [])
                        elif msg_type == "rag_debug":
                            rag_debug = data.get("debug", {})
                        elif msg_type == "done":
                            break
                    except json.JSONDecodeError:
                        continue
                
                return {
                    "success": True,
                    "elapsed_ms": int(elapsed * 1000),
                    "response_length": len(full_response),
                    "sources_count": len(sources),
                    "rag_debug": rag_debug,
                    "response_preview": full_response[:200] + "..." if len(full_response) > 200 else full_response
                }
            else:
                return {
                    "success": False,
                    "elapsed_ms": int(elapsed * 1000),
                    "error": f"HTTP {resp.status_code}: {resp.text[:200]}"
                }
        except Exception as e:
            return {
                "success": False,
                "elapsed_ms": int((time.time() - start_time) * 1000),
                "error": str(e)
            }


async def run_tests():
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ —Ç–µ—Å—Ç—ã"""
    print("=" * 80)
    print("RAG SETTINGS TESTER")
    print("=" * 80)
    print(f"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    docs = await get_documents()
    if not docs:
        print("‚ùå No documents found! Please upload a document first.")
        return
    
    print(f"üìÑ Found {len(docs)} document(s):")
    for doc in docs:
        print(f"   - {doc.get('name', 'Unknown')} (ID: {doc.get('id', 'N/A')[:8]}...)")
    print()
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è —Ç–µ—Å—Ç–æ–≤
    doc_id = docs[0].get("id")
    doc_name = docs[0].get("name", "Unknown")
    
    print(f"üìã Testing with document: {doc_name}")
    print(f"üìù Test queries: {len(TEST_QUERIES)}")
    print(f"‚öôÔ∏è  Test configs: {len(TEST_CONFIGS)}")
    print(f"üî¢ Total tests: {len(TEST_QUERIES) * len(TEST_CONFIGS)}")
    print()
    
    results = []
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –∫–æ–º–±–∏–Ω–∞—Ü–∏—é
    for config in TEST_CONFIGS:
        config_name = config.get("name", "Unknown")
        print(f"\n{'='*60}")
        print(f"CONFIG: {config_name}")
        print(f"{'='*60}")
        print(f"  chunk_mode: {config.get('chunk_mode')}")
        print(f"  max_chunks: {config.get('max_chunks')}")
        print(f"  chunk_percent: {config.get('chunk_percent')}%")
        print(f"  min_similarity: {config.get('min_similarity')}")
        print(f"  keyword/semantic: {config.get('keyword_weight')}/{config.get('semantic_weight')}")
        print(f"  use_rerank: {config.get('use_rerank')}")
        print()
        
        for test_query in TEST_QUERIES:
            query = test_query["query"]
            query_type = test_query["type"]
            
            print(f"  üîç [{query_type}] \"{query}\"")
            
            result = await test_rag_query(query, config, doc_id)
            
            if result["success"]:
                debug = result.get("rag_debug", {})
                intent = debug.get("intent", {})
                
                print(f"     ‚úÖ {result['elapsed_ms']}ms | {result['sources_count']} sources | {result['response_length']} chars")
                print(f"     üìä scope={intent.get('scope', 'N/A')} | task={intent.get('task', 'N/A')}")
                
                chunk_config = debug.get("chunk_config", {})
                if chunk_config:
                    print(f"     üì¶ target_chunks={chunk_config.get('target_chunks_calculated', 'N/A')}")
            else:
                print(f"     ‚ùå FAILED: {result.get('error', 'Unknown error')[:80]}")
            
            results.append({
                "config": config_name,
                "query": query,
                "query_type": query_type,
                **result
            })
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            await asyncio.sleep(0.5)
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n")
    print("=" * 80)
    print("SUMMARY")
    print("=" * 80)
    
    successful = [r for r in results if r["success"]]
    failed = [r for r in results if not r["success"]]
    
    print(f"‚úÖ Successful: {len(successful)}/{len(results)}")
    print(f"‚ùå Failed: {len(failed)}/{len(results)}")
    
    if successful:
        avg_time = sum(r["elapsed_ms"] for r in successful) / len(successful)
        avg_sources = sum(r["sources_count"] for r in successful) / len(successful)
        print(f"‚è±Ô∏è  Avg response time: {avg_time:.0f}ms")
        print(f"üìö Avg sources: {avg_sources:.1f}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–Ω—Ñ–∏–≥–∞–º
    print("\nüìä Results by config:")
    for config in TEST_CONFIGS:
        config_name = config["name"]
        config_results = [r for r in results if r["config"] == config_name]
        config_success = [r for r in config_results if r["success"]]
        if config_results:
            success_rate = len(config_success) / len(config_results) * 100
            avg_time = sum(r["elapsed_ms"] for r in config_success) / len(config_success) if config_success else 0
            print(f"   {config_name}: {success_rate:.0f}% success, {avg_time:.0f}ms avg")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª
    output_file = f"rag_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"\nüíæ Results saved to: {output_file}")


if __name__ == "__main__":
    asyncio.run(run_tests())
