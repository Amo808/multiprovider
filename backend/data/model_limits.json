{
  "_description": "Token limits for different AI models. Edit this file to adjust RAG context allocation.",
  "_note": "context_limit = total tokens model can handle, rag_context_percent = percentage of limit for RAG context",
  
  "defaults": {
    "context_limit": 8192,
    "rag_context_percent": 70,
    "safety_buffer_tokens": 5000
  },
  
  "models": {
    "gpt-4": {
      "context_limit": 8192,
      "rag_context_percent": 70
    },
    "gpt-4-32k": {
      "context_limit": 32768,
      "rag_context_percent": 70
    },
    "gpt-4-turbo": {
      "context_limit": 128000,
      "rag_context_percent": 70
    },
    "gpt-4o": {
      "context_limit": 128000,
      "rag_context_percent": 70
    },
    "gpt-4o-mini": {
      "context_limit": 128000,
      "rag_context_percent": 70
    },
    "gpt-3.5-turbo": {
      "context_limit": 16385,
      "rag_context_percent": 70
    },
    "gpt-3.5-turbo-16k": {
      "context_limit": 16385,
      "rag_context_percent": 70
    },
    "claude-3-opus": {
      "context_limit": 200000,
      "rag_context_percent": 70
    },
    "claude-3-sonnet": {
      "context_limit": 200000,
      "rag_context_percent": 70
    },
    "claude-3-haiku": {
      "context_limit": 200000,
      "rag_context_percent": 70
    },
    "claude-3.5-sonnet": {
      "context_limit": 200000,
      "rag_context_percent": 70
    },
    "claude-3.5-haiku": {
      "context_limit": 200000,
      "rag_context_percent": 70
    },
    "gemini-1.5-pro": {
      "context_limit": 1000000,
      "rag_context_percent": 70
    },
    "gemini-1.5-flash": {
      "context_limit": 1000000,
      "rag_context_percent": 70
    },
    "gemini-2.0-flash": {
      "context_limit": 1000000,
      "rag_context_percent": 70
    },
    "gemini-pro": {
      "context_limit": 32000,
      "rag_context_percent": 70
    },
    "deepseek-chat": {
      "context_limit": 64000,
      "rag_context_percent": 70
    },
    "deepseek-coder": {
      "context_limit": 64000,
      "rag_context_percent": 70
    },
    "deepseek-reasoner": {
      "context_limit": 64000,
      "rag_context_percent": 70
    },
    "mistral-large": {
      "context_limit": 128000,
      "rag_context_percent": 70
    },
    "mistral-medium": {
      "context_limit": 32000,
      "rag_context_percent": 70
    },
    "mistral-small": {
      "context_limit": 32000,
      "rag_context_percent": 70
    },
    "llama-3.1-70b": {
      "context_limit": 128000,
      "rag_context_percent": 70
    },
    "llama-3.1-8b": {
      "context_limit": 128000,
      "rag_context_percent": 70
    }
  }
}
