# Изменения для бесконечного ожидания OpenAI ответов

## Описание проблемы
Нужно было сделать так, чтобы приложение ждало ответ от OpenAI сколько угодно долго (даже 15+ минут), не прерывая соединение и показывая пользователю результат когда он в итоге придет.

## Внесенные изменения

### 1. Backend: OpenAI Provider (`adapters/openai_provider.py`)
- **Убраны все искусственные ограничения по времени:**
  - Удалены `max_consecutive_timeouts = 5` и `max_empty_lines = 10`
  - Изменен `timeout_duration` с 30-60 сек на 15 сек (только для heartbeat)
- **Добавлен бесконечный heartbeat:**
  - Каждые 15 секунд отправляется heartbeat если нет новых токенов
  - Heartbeat включает информацию о времени молчания и прогрессивные сообщения
- **Улучшена логика обработки тишины:**
  - Отслеживается `last_token_time` и `silence_duration`
  - Прогрессивные сообщения: 60с → 5мин → 15мин → 15мин+
  - Никогда не прерывается соединение из-за времени

### 2. Backend: Gemini Provider (`adapters/gemini_provider.py`)
- **Убрано ограничение `max_empty_chunks`:**
  - Раньше: прерывалось после 200-500 пустых чанков
  - Теперь: никогда не прерывается, только отправляет heartbeat
- **Добавлен heartbeat каждые 15 секунд тишины**
- **Прогрессивные сообщения о времени ожидания**

### 3. Backend: Server Configuration (`backend/main.py`)
- **Увеличен `timeout_keep_alive` до 600 секунд (10 минут)**
- **Добавлен `timeout_graceful_shutdown=60`**

### 4. Production Scripts (`backend/start_production.sh`)
- **Gunicorn настроен с `--timeout 0` (бесконечный таймаут)**
- **Увеличен `--keep-alive` до 600 секунд**

### 5. Docker Configuration (`Dockerfile`)
- **Изменена команда запуска:**
  - Было: `CMD ["python", "backend/main.py"]`
  - Стало: `CMD ["uvicorn", "backend.main:app", "--host", "0.0.0.0", "--port", "10000", "--timeout-keep-alive", "600"]`

### 6. Frontend: Connection Timeouts (`frontend/src/hooks/useConversations.ts`)
- **Увеличены все таймауты для очень долгих запросов:**
  - `HEARTBEAT_TIMEOUT`: 180с → 600с (10 минут)
  - `REASONING_HEARTBEAT_TIMEOUT`: 300с → 1800с (30 минут)
  - `STREAMING_TIMEOUT`: 1800с → 3600с (60 минут)

### 7. Frontend: API Client (`frontend/src/services/api.ts`)
- **Подтверждено отсутствие таймаутов в fetch запросах**
- **Комментарий "No timeout - allow infinite response time" уже присутствовал**

## Результат

Теперь приложение:

1. **Никогда не прерывает соединение** из-за времени ожидания
2. **Отправляет heartbeat каждые 15 секунд** для поддержания соединения
3. **Показывает прогрессивные сообщения** о том, сколько времени прошло
4. **Дождется ответа OpenAI** даже если он придет через 15+ минут
5. **Корректно обрабатывает reasoning запросы** с высокой сложностью

## Технические ограничения

- **Render.com**: может иметь жесткий лимит на время запроса (обычно 15-30 минут)
- **Браузер**: может закрыть соединение после очень долгого ожидания без активности
- **OpenAI API**: может сам прервать соединение при внутренних ошибках
- **Сетевая инфраструктура**: прокси и firewalls могут иметь свои ограничения

## Тестирование

Для тестирования долгих запросов:
1. Используйте GPT-5 с `reasoning_effort: "high"`
2. Отправьте сложный запрос требующий долгого размышления
3. Проверьте что heartbeat сообщения приходят каждые 15 секунд
4. Убедитесь что соединение не прерывается через 5-10 минут

## Мониторинг

В логах backend будут видны:
- `[OPENAI] Heartbeat timeout #N after Xs total, Ys since last token`
- Прогрессивные stage_message с информацией о времени ожидания
- Отсутствие сообщений о принудительном завершении из-за таймаутов
