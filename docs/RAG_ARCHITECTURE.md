# üß† RAG Architecture - –ü–æ–ª–Ω–∞—è –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –°–∏—Å—Ç–µ–º—ã

## üìã –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ

1. [–û–±–∑–æ—Ä –°–∏—Å—Ç–µ–º—ã](#–æ–±–∑–æ—Ä-—Å–∏—Å—Ç–µ–º—ã)
2. [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Pipeline](#–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞-pipeline)
3. [–ê–≥–µ–Ω—Ç—ã –∏ –ò—Ö –†–æ–ª–∏](#–∞–≥–µ–Ω—Ç—ã-–∏-–∏—Ö-—Ä–æ–ª–∏)
4. [–ú–µ—Ç–æ–¥—ã –ü–æ–∏—Å–∫–∞](#–º–µ—Ç–æ–¥—ã-–ø–æ–∏—Å–∫–∞)
5. [–ü—Ä–æ–º–ø—Ç—ã –°–∏—Å—Ç–µ–º—ã](#–ø—Ä–æ–º–ø—Ç—ã-—Å–∏—Å—Ç–µ–º—ã)
6. [–ê–ª–≥–æ—Ä–∏—Ç–º—ã –í—ã–±–æ—Ä–∞ –ß–∞–Ω–∫–æ–≤](#–∞–ª–≥–æ—Ä–∏—Ç–º—ã-–≤—ã–±–æ—Ä–∞-—á–∞–Ω–∫–æ–≤)
7. [Flow –î–∏–∞–≥—Ä–∞–º–º—ã](#flow-–¥–∏–∞–≥—Ä–∞–º–º—ã)
8. [–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã](#–Ω–∞—Å—Ç—Ä–æ–π–∫–∏-–∏-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã)

***

## üéØ –û–±–∑–æ—Ä –°–∏—Å—Ç–µ–º—ã

### –ß—Ç–æ —Ç–∞–∫–æ–µ —ç—Ç–∞ RAG —Å–∏—Å—Ç–µ–º–∞?

–≠—Ç–æ **—É–º–Ω–∞—è –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞** –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏, –∫–æ—Ç–æ—Ä–∞—è:

* üß† **–ü–æ–Ω–∏–º–∞–µ—Ç –Ω–∞–º–µ—Ä–µ–Ω–∏—è** –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ AI –∞–Ω–∞–ª–∏–∑
* üîç **–í—ã–±–∏—Ä–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é** –ø–æ–∏—Å–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
* üìö **–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ª—é–±—ã–µ –æ–±—ä–µ–º—ã** –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–æ—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –¥–æ —Ü–µ–ª–æ–π –∫–Ω–∏–≥–∏)
* üéØ **–ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏** RAG (HyDE, Multi-Query, Agentic, etc.)
* ü§ñ **–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–≥–µ–Ω—Ç–æ–≤** –¥–ª—è –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏ —Å–∏–Ω—Ç–µ–∑–∞

### –û—Å–Ω–æ–≤–Ω—ã–µ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    USER QUERY                                ‚îÇ
‚îÇ              "–û —á–µ–º 40 –≥–ª–∞–≤–∞ –∫–Ω–∏–≥–∏?"                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              üß† INTENT ANALYZER (AI Agent)                   ‚îÇ
‚îÇ  –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç:                           ‚îÇ
‚îÇ  ‚Ä¢ Scope: single_section / full_document / search           ‚îÇ
‚îÇ  ‚Ä¢ Task: summarize / analyze / find_loopholes               ‚îÇ
‚îÇ  ‚Ä¢ Sections: [40] –∏–ª–∏ [] –¥–ª—è –ø–æ–∏—Å–∫–∞                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            üìä STRATEGY SELECTOR                              ‚îÇ
‚îÇ  –í—ã–±–∏—Ä–∞–µ—Ç –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞:                                     ‚îÇ
‚îÇ  ‚Ä¢ Full Document Load                                       ‚îÇ
‚îÇ  ‚Ä¢ Chapter Load                                             ‚îÇ
‚îÇ  ‚Ä¢ Semantic Search (HyDE/Multi-Query/Agentic)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚ñº           ‚ñº           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ FULL    ‚îÇ ‚îÇ CHAPTER ‚îÇ ‚îÇ SEARCH  ‚îÇ
    ‚îÇ MODE    ‚îÇ ‚îÇ MODE    ‚îÇ ‚îÇ MODE    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ           ‚îÇ           ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  CONTEXT BUILDER      ‚îÇ
         ‚îÇ  ‚Ä¢ –°–æ–±–∏—Ä–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç   ‚îÇ
         ‚îÇ  ‚Ä¢ –î–æ–±–∞–≤–ª—è–µ—Ç citations‚îÇ
         ‚îÇ  ‚Ä¢ –°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç      ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ ADAPTIVE COMPRESSION  ‚îÇ
         ‚îÇ –°–∂–∏–º–∞–µ—Ç –ø–æ–¥ –ª–∏–º–∏—Ç—ã    ‚îÇ
         ‚îÇ –º–æ–¥–µ–ª–∏ (70% window)   ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ   FINAL RESPONSE      ‚îÇ
         ‚îÇ   + Sources + Debug   ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

***

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Pipeline

### 1Ô∏è‚É£ Entry Point: `smart_rag_search()`

**–í—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:**

* `query` - –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
* `user_email` - email –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
* `document_id` - ID –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
* `max_tokens` - –º–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ (default: 50,000)

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:**

1. –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–≥–ª–∞–≤—ã, —á–∞–Ω–∫–∏)
2. –í—ã–∑—ã–≤–∞–µ—Ç Intent Analyzer
3. –í—ã–±–∏—Ä–∞–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ intent
4. –°—Ç—Ä–æ–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç
5. –ü—Ä–∏–º–µ–Ω—è–µ—Ç adaptive compression
6. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç

### 2Ô∏è‚É£ Modes of Operation

| Mode | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è | –ß—Ç–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è |
|------|-------------------|-----------------|
| **Full Document** | "–û —á–µ–º –≤—Å—è –∫–Ω–∏–≥–∞?", "–ü–µ—Ä–µ—Å–∫–∞–∂–∏ –≤–µ—Å—å –¥–æ–∫—É–º–µ–Ω—Ç" | –í–µ—Å—å –¥–æ–∫—É–º–µ–Ω—Ç —Ü–µ–ª–∏–∫–æ–º (—Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π batch –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥–ª—è –±–æ–ª—å—à–∏—Ö) |
| **Single Section** | "–û —á–µ–º –≥–ª–∞–≤–∞ 40?", "–ß—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç —Å—Ç–∞—Ç—å—è 228?" | –û–¥–Ω–∞ –≥–ª–∞–≤–∞/—Å–µ–∫—Ü–∏—è —Ü–µ–ª–∏–∫–æ–º |
| **Multiple Sections** | "–ü–µ—Ä–µ—Å–∫–∞–∂–∏ –≥–ª–∞–≤—ã 1-5", "–°—Ä–∞–≤–Ω–∏ —Å—Ç–∞—Ç—å–∏ 159 –∏ 160" | –ù–µ—Å–∫–æ–ª—å–∫–æ –≥–ª–∞–≤ —Ü–µ–ª–∏–∫–æ–º |
| **Comparison** | "–°—Ä–∞–≤–Ω–∏ –≥–ª–∞–≤—ã X –∏ Y" | –ù–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—Ü–∏–π —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è |
| **Semantic Search** | "–ì–¥–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è X?", "–ù–∞–π–¥–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ Y" | Top-K —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ —á–µ—Ä–µ–∑ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ |

***

## ü§ñ –ê–≥–µ–Ω—Ç—ã –∏ –ò—Ö –†–æ–ª–∏

### –ê–≥–µ–Ω—Ç #1: Intent Analyzer (AI-powered)

**–ú–æ–¥–µ–ª—å:** GPT-4o-mini\
**–ó–∞–¥–∞—á–∞:** –ü–æ–Ω—è—Ç—å –ß–¢–û —Ö–æ—á–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å

**–ü—Ä–æ–º–ø—Ç:**

```
Analyze this user query about a document and determine the best retrieval strategy.

USER QUERY: "{query}"

DOCUMENT STRUCTURE:
{structure_desc}

Analyze the query and return a JSON object with these fields:

1. "scope": One of:
   - "single_section": User wants a specific chapter/article/section
   - "multiple_sections": User wants several specific sections
   - "full_document": User wants to analyze the entire document
   - "comparison": User wants to compare different parts
   - "search": User is looking for specific information

2. "sections": Array of section identifiers the user wants
   - ["40"] for chapter 40
   - ["1", "2", "3"] for sections 1-3
   - [] for full document or search scope

3. "task": One of:
   - "summarize": Retell, summarize, explain content
   - "analyze": Deep analysis, themes, meaning
   - "find_loopholes": Find legal loopholes, exceptions
   - "find_contradictions": Find contradictions
   - "find_penalties": Find penalties, sanctions, fines
   - "compare": Compare sections
   - "search": Find specific information

4. "search_query": If scope is "search", provide optimized search query

5. "reasoning": Brief explanation of your analysis
```

**–ü—Ä–∏–º–µ—Ä—ã —Ä–∞–±–æ—Ç—ã:**

| User Query | Scope | Sections | Task |
|------------|-------|----------|------|
| "–û —á–µ–º –≥–ª–∞–≤–∞ 40?" | single\_section | \["40"] | summarize |
| "–ü–µ—Ä–µ—Å–∫–∞–∂–∏ –≥–ª–∞–≤—ã 1-5" | multiple\_sections | \["1","2","3","4","5"] | summarize |
| "–û —á–µ–º –≤—Å—è –∫–Ω–∏–≥–∞?" | full\_document | \[] | summarize |
| "–ù–∞–π–¥–∏ –ª–∞–∑–µ–π–∫–∏ –≤ –∑–∞–∫–æ–Ω–µ" | search | \[] | find\_loopholes |
| "–°—Ä–∞–≤–Ω–∏ —Å—Ç–∞—Ç—å–∏ 159 –∏ 160" | comparison | \["159","160"] | compare |

**Fallback:** –ï—Å–ª–∏ OpenAI API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è regex-based –∞–Ω–∞–ª–∏–∑.

***

### –ê–≥–µ–Ω—Ç #2: HyDE Agent (Hypothetical Document Embeddings)

**–ú–æ–¥–µ–ª—å:** GPT-4o-mini\
**–ó–∞–¥–∞—á–∞:** –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è:**

* Query —Å–æ–¥–µ—Ä–∂–∏—Ç "—Å—Ç—Ä–∞–Ω–∏—Ü–∞", "—Ü–∏—Ç–∞—Ç–∞", "–∞–±–∑–∞—Ü"
* –ù—É–∂–µ–Ω —Ç–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

**–ü—Ä–æ–º–ø—Ç:**

```
Given this question, write a detailed passage that would answer it.
Write as if you are quoting directly from a document that contains this information.
Be specific and detailed. Write 2-3 paragraphs.

Question: {query}

Hypothetical document passage:
```

**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç:**

1. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç-–æ—Ç–≤–µ—Ç
2. –°–æ–∑–¥–∞–µ—Ç embedding —ç—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
3. –ò—â–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã, –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π
4. –†–µ–∑—É–ª—å—Ç–∞—Ç: –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤

**–ü—Ä–∏–º–µ—Ä:**

```
Query: "–ß—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç –∑–∞–∫–æ–Ω –æ —Å—Ä–æ–∫–∞—Ö –¥–∞–≤–Ω–æ—Å—Ç–∏?"

HyDE –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç:
"–°—Ä–æ–∫ –∏—Å–∫–æ–≤–æ–π –¥–∞–≤–Ω–æ—Å—Ç–∏ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç—Ä–∏ –≥–æ–¥–∞ —Å–æ –¥–Ω—è, –∫–æ–≥–¥–∞ –ª–∏—Ü–æ 
—É–∑–Ω–∞–ª–æ –∏–ª–∏ –¥–æ–ª–∂–Ω–æ –±—ã–ª–æ —É–∑–Ω–∞—Ç—å –æ –Ω–∞—Ä—É—à–µ–Ω–∏–∏ —Å–≤–æ–µ–≥–æ –ø—Ä–∞–≤–∞. 
–í –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–ª—É—á–∞—è—Ö —Å—Ä–æ–∫ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ–¥–ª–µ–Ω –¥–æ –¥–µ—Å—è—Ç–∏ –ª–µ—Ç..."

–ó–∞—Ç–µ–º –∏—â–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã, –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç.
```

***

### –ê–≥–µ–Ω—Ç #3: Multi-Query Agent

**–ú–æ–¥–µ–ª—å:** GPT-4o-mini\
**–ó–∞–¥–∞—á–∞:** –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è:**

* –®–∏—Ä–æ–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã ("–æ —á–µ–º", "—á—Ç–æ —Ç–∞–∫–æ–µ", "–æ–±–∑–æ—Ä")
* Default —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è search mode

**–ü—Ä–æ–º–ø—Ç:**

```
Generate {num_queries} different search queries based on this original query.
Each query should explore a different aspect or use different phrasing.

Original query: {query}

Generate queries that would help find comprehensive information.
Return as JSON array of strings.
```

**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç:**

1. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç 3-4 –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞
2. –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –ø–æ –∫–∞–∂–¥–æ–º—É
3. –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ chunk\_id)
4. Rerank –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏

**–ü—Ä–∏–º–µ—Ä:**

```
Original: "–û —á–µ–º –≥–ª–∞–≤–∞ –ø—Ä–æ –≥–µ—Ä–æ—è?"

Generated queries:
1. "–≥–ª–∞–≤–Ω—ã–π –≥–µ—Ä–æ–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –æ–ø–∏—Å–∞–Ω–∏–µ"
2. "—Å–æ–±—ã—Ç–∏—è —Å –≥–ª–∞–≤–Ω—ã–º –≥–µ—Ä–æ–µ–º"
3. "—Ä–∞–∑–≤–∏—Ç–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –≥–ª–∞–≤–Ω–æ–≥–æ –≥–µ—Ä–æ—è"
4. "—Ä–æ–ª—å –≥–ª–∞–≤–Ω–æ–≥–æ –≥–µ—Ä–æ—è –≤ —Å—é–∂–µ—Ç–µ"
```

***

### –ê–≥–µ–Ω—Ç #4: Agentic Retrieval Agent

**–ú–æ–¥–µ–ª—å:** GPT-4o-mini\
**–ó–∞–¥–∞—á–∞:** –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ –∏—Å–∫–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, —Ä–µ—à–∞—è —Å–∞–º —á—Ç–æ –∏—Å–∫–∞—Ç—å –¥–∞–ª—å—à–µ

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è:**

* –°–ª–æ–∂–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã, —Ç—Ä–µ–±—É—é—â–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–∏—Å–∫–æ–≤
* –Ø–≤–Ω–æ —É–∫–∞–∑–∞–Ω–æ `strategy="agentic"`

**–ü—Ä–æ–º–ø—Ç (—Ü–∏–∫–ª):**

```
You are a research agent helping to find information in documents.
Your task is to find information to answer: "{query}"

You have access to a document search tool. For each iteration:
1. Analyze what information you still need
2. Generate a specific search query
3. Review results and decide if you need more searches

Current search history:
{history}

Based on what you've found, what should be the next search query?
If you have enough information, respond with "DONE".

Next search query (or DONE):
```

**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç:**

1. Iteration 1: –ê–≥–µ–Ω—Ç —Ä–µ—à–∞–µ—Ç —á—Ç–æ –∏—Å–∫–∞—Ç—å –ø–µ—Ä–≤—ã–º
2. –°–∏—Å—Ç–µ–º–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫
3. Iteration 2: –ê–≥–µ–Ω—Ç —Å–º–æ—Ç—Ä–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —Ä–µ—à–∞–µ—Ç –Ω—É–∂–Ω–æ –ª–∏ –µ—â–µ
4. –ü–æ–≤—Ç–æ—Ä—è–µ—Ç –¥–æ 3 –∏—Ç–µ—Ä–∞—Ü–∏–π –∏–ª–∏ –ø–æ–∫–∞ –∞–≥–µ–Ω—Ç –Ω–µ —Å–∫–∞–∂–µ—Ç "DONE"
5. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

**–ü—Ä–∏–º–µ—Ä:**

```
Query: "–ö–∞–∫–æ–≤—ã –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è –Ω–∞—Ä—É—à–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏ 228?"

Iteration 1: –ê–≥–µ–Ω—Ç –∏—â–µ—Ç "—Å—Ç–∞—Ç—å—è 228 –Ω–∞–∫–∞–∑–∞–Ω–∏–µ —Å–∞–Ω–∫—Ü–∏–∏"
‚Üí –ù–∞—Ö–æ–¥–∏—Ç 5 —á–∞–Ω–∫–æ–≤

Iteration 2: –ê–≥–µ–Ω—Ç –∏—â–µ—Ç "228 —à—Ç—Ä–∞—Ñ –ª–∏—à–µ–Ω–∏–µ —Å–≤–æ–±–æ–¥—ã —Å—Ä–æ–∫–∏"
‚Üí –ù–∞—Ö–æ–¥–∏—Ç 3 –Ω–æ–≤—ã—Ö —á–∞–Ω–∫–∞

Iteration 3: –ê–≥–µ–Ω—Ç —Ä–µ—à–∞–µ—Ç "DONE" (–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏)

–ò—Ç–æ–≥–æ: 8 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
```

***

### –ê–≥–µ–Ω—Ç #5: Step-Back Prompting Agent

**–ú–æ–¥–µ–ª—å:** GPT-4o-mini\
**–ó–∞–¥–∞—á–∞:** –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –æ–±—â–∏–π –≤–æ–ø—Ä–æ—Å –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è:**

* –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤–º–µ—Å—Ç–µ —Å HyDE –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤

**–ü—Ä–æ–º–ø—Ç:**

```
Given a specific question, generate a more general "step-back" question 
that would help understand the broader context needed to answer the original question.

Specific question: {query}

Step-back question (more general):
```

**–ü—Ä–∏–º–µ—Ä:**

```
Specific: "–ö–∞–∫–æ–π —à—Ç—Ä–∞—Ñ –∑–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –Ω–∞—Ä—É—à–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ 228?"

Step-back: "–ö–∞–∫–∏–µ –≤–æ–æ–±—â–µ —à—Ç—Ä–∞—Ñ—ã –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω—ã —Å—Ç–∞—Ç—å–µ–π 228?"
```

–°–∏—Å—Ç–µ–º–∞ –∏—â–µ—Ç –ø–æ –æ–±–æ–∏–º –≤–æ–ø—Ä–æ—Å–∞–º –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.

***

### –ê–≥–µ–Ω—Ç #6: Reranking Agent

**–ú–æ–¥–µ–ª—å:** GPT-4o-mini\
**–ó–∞–¥–∞—á–∞:** –ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è:**

* –í–°–ï–ì–î–ê –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
* –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–µ–Ω –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏

**–ü—Ä–æ–º–ø—Ç:**

```
Rate how relevant each of these document chunks is to answering the query.
Rate from 0.0 (not relevant) to 1.0 (highly relevant).

Query: {query}

Documents:
[1] {chunk1}
[2] {chunk2}
...

Return JSON array of scores: [0.9, 0.7, 0.5, ...]
```

**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç:**

1. –ü–æ–ª—É—á–∞–µ—Ç 10-20 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –æ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
2. LLM –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞–∂–¥—ã–π –æ—Ç 0.0 –¥–æ 1.0
3. –°–æ—Ä—Ç–∏—Ä—É–µ—Ç –ø–æ –Ω–æ–≤—ã–º –æ—Ü–µ–Ω–∫–∞–º
4. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç top-K (–æ–±—ã—á–Ω–æ 5-10)

**–ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ:**

* –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –º–æ–∂–µ—Ç –¥–∞–≤–∞—Ç—å –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è
* LLM –ª—É—á—à–µ –ø–æ–Ω–∏–º–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
* –ü–æ–≤—ã—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ 20-30%

***

## üîç –ú–µ—Ç–æ–¥—ã –ü–æ–∏—Å–∫–∞ (Retrieval Strategies)

### 1. Vector Search (Semantic)

**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è:** OpenAI Embeddings (text-embedding-3-small)\
**–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö:** Supabase + pgvector

**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç:**

```sql
-- –§—É–Ω–∫—Ü–∏—è –≤ PostgreSQL
CREATE FUNCTION search_document_chunks_v2(
    query_embedding vector(1536),
    match_count int,
    filter_user_id uuid,
    filter_document_id uuid,
    similarity_threshold float
)
RETURNS TABLE (
    id uuid,
    document_id uuid,
    content text,
    chunk_index int,
    metadata jsonb,
    similarity float
)
AS $$
    SELECT 
        id,
        document_id,
        content,
        chunk_index,
        metadata,
        1 - (embedding <=> query_embedding) as similarity
    FROM document_chunks
    WHERE user_id = filter_user_id
        AND (filter_document_id IS NULL OR document_id = filter_document_id)
        AND 1 - (embedding <=> query_embedding) > similarity_threshold
    ORDER BY embedding <=> query_embedding
    LIMIT match_count;
$$ LANGUAGE sql;
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**

* Threshold: 0.5 (default) - –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å
* Limit: 5-20 —á–∞–Ω–∫–æ–≤
* Distance metric: Cosine similarity

***

### 2. Hybrid Search (BM25 + Vector)

**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è:** PostgreSQL full-text search + pgvector

**–§–æ—Ä–º—É–ª–∞:**

```
final_score = (vector_weight √ó vector_score) + (keyword_weight √ó bm25_score)
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**

* `vector_weight`: 0.7 (default) - –≤–µ—Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
* `keyword_weight`: 0.3 (default) - –≤–µ—Å keyword –ø–æ–∏—Å–∫–∞

**SQL:**

```sql
CREATE FUNCTION hybrid_search_chunks_v2(
    query_text text,
    query_embedding vector(1536),
    match_count int,
    filter_user_id uuid,
    vector_weight float,
    keyword_weight float
)
RETURNS TABLE (...)
AS $$
    WITH vector_search AS (
        SELECT *, 1 - (embedding <=> query_embedding) as vector_score
        FROM document_chunks
        WHERE user_id = filter_user_id
    ),
    keyword_search AS (
        SELECT *, ts_rank(search_vector, plainto_tsquery(query_text)) as keyword_score
        FROM document_chunks
        WHERE user_id = filter_user_id
            AND search_vector @@ plainto_tsquery(query_text)
    )
    SELECT 
        v.*,
        (vector_weight * v.vector_score + keyword_weight * COALESCE(k.keyword_score, 0)) as combined_score
    FROM vector_search v
    LEFT JOIN keyword_search k ON v.id = k.id
    ORDER BY combined_score DESC
    LIMIT match_count;
$$ LANGUAGE sql;
```

**–ö–æ–≥–¥–∞ –ª—É—á—à–µ:**

* Keyword –ø–æ–∏—Å–∫: —Ç–æ—á–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã, –∏–º–µ–Ω–∞, –¥–∞—Ç—ã
* Vector –ø–æ–∏—Å–∫: —Å–µ–º–∞–Ω—Ç–∏–∫–∞, —Å–∏–Ω–æ–Ω–∏–º—ã, –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏–µ
* Hybrid: –ª—É—á—à–µ–µ –∏–∑ –æ–±–æ–∏—Ö –º–∏—Ä–æ–≤

***

### 3. HyDE Search

**–ê–ª–≥–æ—Ä–∏—Ç–º:**

1. LLM –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç (2-3 –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞)
2. –°–æ–∑–¥–∞–µ—Ç—Å—è embedding –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
3. –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ —ç—Ç–æ–º—É embedding
4. –†–µ–∑—É–ª—å—Ç–∞—Ç: –¥–æ–∫—É–º–µ–Ω—Ç—ã, –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ "–∏–¥–µ–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç"

**–ö–æ–¥:**

```python
# Step 1: Generate hypothetical doc
response = openai.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": hyde_prompt}],
    temperature=0.7,
    max_tokens=500
)
hypothetical_doc = response.choices[0].message.content

# Step 2: Embed hypothetical doc
hyde_embedding = create_embedding(hypothetical_doc)

# Step 3: Search with this embedding
results = vector_search(hyde_embedding)
```

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**

* –í–æ–ø—Ä–æ—Å—ã —Ç–∏–ø–∞ "–æ —á–µ–º –≥–ª–∞–≤–∞ X?"
* –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–∏
* –ö–æ–≥–¥–∞ –Ω—É–∂–Ω—ã —Ç–æ—á–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Ç–µ–∫—Å—Ç–∞

***

### 4. Multi-Query Search

**–ê–ª–≥–æ—Ä–∏—Ç–º:**

1. LLM –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç 3-4 –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞
2. Hybrid search –ø–æ –∫–∞–∂–¥–æ–º—É –∑–∞–ø—Ä–æ—Å—É
3. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è)
4. Reranking –≤—Å–µ—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤

**–ö–æ–¥:**

```python
# Generate alternative queries
queries = llm.generate_queries(original_query, num=4)

# Search with each
all_results = []
for q in queries:
    results = hybrid_search(q, limit=7)
    for r in results:
        r["matching_queries"] = [q]
    all_results.extend(results)

# Deduplicate
unique_results = deduplicate_by_chunk_id(all_results)

# Rerank
final_results = rerank(unique_results, original_query, top_k=10)
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**

* –õ—É—á—à–µ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
* –ù–∞—Ö–æ–¥–∏—Ç —Å–∏–Ω–æ–Ω–∏–º—ã –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ–º—ã
* –£—Å—Ç–æ–π—á–∏–≤ –∫ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–µ –≤–æ–ø—Ä–æ—Å–∞

***

## üìù –ü—Ä–æ–º–ø—Ç—ã –°–∏—Å—Ç–µ–º—ã

### Intent Analysis Prompt

```
Analyze this user query about a document and determine the best retrieval strategy.

USER QUERY: "{query}"

DOCUMENT STRUCTURE:
Document type: {doc_type}
Total chapters: {num_chapters}
Chapter numbers: {chapter_list}
Total content chunks: {num_chunks}

Analyze the query and return a JSON object with these fields:

1. "scope": One of:
   - "single_section": User wants a specific chapter/article/section/—Å—Ç–∞—Ç—å—è/–ø—É–Ω–∫—Ç
   - "multiple_sections": User wants several specific sections (e.g., "—Å—Ç–∞—Ç—å–∏ 1-5")
   - "full_document": User wants to analyze the entire document (summary, overview)
   - "comparison": User wants to compare different parts of the document
   - "search": User is looking for specific information that could be anywhere

2. "sections": Array of section identifiers the user wants. Examples:
   - ["40"] for chapter/article 40
   - ["1", "2", "3"] for sections 1-3
   - [] for full document or search scope

3. "task": One of:
   - "summarize": Retell, summarize, explain content
   - "analyze": Deep analysis, themes, meaning
   - "find_loopholes": Find legal loopholes, exceptions, workarounds
   - "find_contradictions": Find contradictions, inconsistencies
   - "find_penalties": Find penalties, sanctions, fines
   - "find_requirements": Find requirements, obligations
   - "compare": Compare sections or analyze relationships
   - "search": Find specific information

4. "search_query": If scope is "search", provide an optimized search query

5. "reasoning": Brief explanation of your analysis (1-2 sentences)

EXAMPLES:
- "—Ä–∞—Å—Å–∫–∞–∂–∏ –æ 40 –≥–ª–∞–≤–µ" -> {"scope": "single_section", "sections": ["40"], "task": "summarize"}
- "–æ —á–µ–º –≤—Å—è –∫–Ω–∏–≥–∞?" -> {"scope": "full_document", "sections": [], "task": "summarize"}
- "–Ω–∞–π–¥–∏ –ª–∞–∑–µ–π–∫–∏" -> {"scope": "search", "sections": [], "task": "find_loopholes", "search_query": "–∏—Å–∫–ª—é—á–µ–Ω–∏–µ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –ª—å–≥–æ—Ç–∞"}

Respond with ONLY valid JSON, no markdown formatting.
```

***

### Task-Specific Instructions

–î–æ–±–∞–≤–ª—è—é—Ç—Å—è –í –ù–ê–ß–ê–õ–û –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ –º–æ–¥–µ–ª—å:

#### Summarize Task

```
üìù –ó–ê–î–ê–ß–ê: –ü–µ—Ä–µ—Å–∫–∞–∂–∏/—Å—É–º–º–∞—Ä–∏–∑–∏—Ä—É–π —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –Ω–∏–∂–µ.
```

#### Analyze Task

```
üîç –ó–ê–î–ê–ß–ê: –ü—Ä–æ–≤–µ–¥–∏ –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ - —Ç–µ–º—ã, —Å–º—ã—Å–ª, –ø–æ–¥—Ç–µ–∫—Å—Ç.
```

#### Find Loopholes Task

```
‚öñÔ∏è –ó–ê–î–ê–ß–ê: –ù–∞–π–¥–∏ –ª–∞–∑–µ–π–∫–∏, –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∏ —Å–ø–æ—Å–æ–±—ã –æ–±—Ö–æ–¥–∞ –≤ —Ç–µ–∫—Å—Ç–µ.
–û–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞:
- –§—Ä–∞–∑—ã —Ç–∏–ø–∞ "–∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º", "–∫—Ä–æ–º–µ —Å–ª—É—á–∞–µ–≤", "–µ—Å–ª–∏ –Ω–µ..."
- –†–∞–∑–º—ã—Ç—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏
- –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —á–µ—Ç–∫–∏—Ö –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π
- –ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è —Å –¥—Ä—É–≥–∏–º–∏ –Ω–æ—Ä–º–∞–º–∏
```

#### Find Contradictions Task

```
‚ö° –ó–ê–î–ê–ß–ê: –ù–∞–π–¥–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –≤ —Ç–µ–∫—Å—Ç–µ.
–ò—â–∏:
- –í–∑–∞–∏–º–æ–∏—Å–∫–ª—é—á–∞—é—â–∏–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
- –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –Ω–µ—Å—Ç—ã–∫–æ–≤–∫–∏
- –†–∞–∑–Ω–æ—á—Ç–µ–Ω–∏—è –≤ —Ç–µ—Ä–º–∏–Ω–∞—Ö
```

#### Compare Task

```
üìä –ó–ê–î–ê–ß–ê: –°—Ä–∞–≤–Ω–∏ —É–∫–∞–∑–∞–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã. –ù–∞–π–¥–∏ –æ–±—â–µ–µ –∏ —Ä–∞–∑–ª–∏—á–∏—è.
```

***

### RAG Context Header

–î–æ–±–∞–≤–ª—è–µ—Ç—Å—è –ø–µ—Ä–µ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏:

```
–ò—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–¥—É—é—â–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–∫–∞–∂–∏ –Ω–æ–º–µ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–∞ [1], [2] –∏ —Ç.–¥.
–ï—Å–ª–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –Ω–µ—Ç –Ω—É–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º.

---
–ù–ê–ô–î–ï–ù–ù–´–ï –î–û–ö–£–ú–ï–ù–¢–´:

[1] üìÑ –î–æ–∫—É–º–µ–Ω—Ç.pdf | ¬ß –ì–ª–∞–≤–∞ 5 | —Ñ—Ä–∞–≥–º–µ–Ω—Ç 23
{content}

[2] üìÑ –î–æ–∫—É–º–µ–Ω—Ç.pdf | ¬ß –ì–ª–∞–≤–∞ 6 | —Ñ—Ä–∞–≥–º–µ–Ω—Ç 45
{content}
...
```

***

## üéØ –ê–ª–≥–æ—Ä–∏—Ç–º—ã –í—ã–±–æ—Ä–∞ –ß–∞–Ω–∫–æ–≤

### Decision Tree

```
START: User Query
‚îÇ
‚îú‚îÄ Intent Analysis
‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ scope = "full_document"
‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Check document size
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ < 400K chars ‚Üí Load all chunks
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ > 400K chars ‚Üí Iterative batching
‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ Return: All document content
‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ scope = "single_section"
‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Extract section number from intent
‚îÇ  ‚îÇ  ‚îú‚îÄ Get chapter boundaries
‚îÇ  ‚îÇ  ‚îî‚îÄ Return: All chunks in that chapter
‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ scope = "multiple_sections"
‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Extract section numbers
‚îÇ  ‚îÇ  ‚îú‚îÄ Get each chapter content
‚îÇ  ‚îÇ  ‚îî‚îÄ Return: Combined chapters
‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ scope = "search"
‚îÇ     ‚îÇ
‚îÇ     ‚îú‚îÄ Detect query type
‚îÇ     ‚îÇ  ‚îú‚îÄ specific (—Å—Ç—Ä–∞–Ω–∏—Ü–∞, —Ü–∏—Ç–∞—Ç–∞) ‚Üí HyDE
‚îÇ     ‚îÇ  ‚îú‚îÄ broad (–æ —á–µ–º, –æ–±–∑–æ—Ä) ‚Üí Multi-Query
‚îÇ     ‚îÇ  ‚îî‚îÄ default ‚Üí Multi-Query
‚îÇ     ‚îÇ
‚îÇ     ‚îú‚îÄ Execute search strategy
‚îÇ     ‚îÇ  ‚îú‚îÄ Get 10-20 candidates
‚îÇ     ‚îÇ  ‚îú‚îÄ Rerank to top 5-10
‚îÇ     ‚îÇ  ‚îî‚îÄ Return: Top-K most relevant chunks
‚îÇ     ‚îÇ
‚îÇ     ‚îî‚îÄ Build context with citations
‚îÇ
‚îî‚îÄ Adaptive Compression
   ‚îÇ
   ‚îú‚îÄ Calculate model context limit
   ‚îú‚îÄ Target: 70% of limit - 5000 tokens
   ‚îú‚îÄ If over: Remove least important chunks
   ‚îî‚îÄ Return: Compressed context
```

***

### Chunk Selection Scoring

–ö–∞–∂–¥—ã–π —á–∞–Ω–∫ –ø–æ–ª—É—á–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ—Ü–µ–Ω–æ–∫:

1. **Vector Similarity Score** (0.0 - 1.0)
   * Cosine similarity –º–µ–∂–¥—É embedding –∑–∞–ø—Ä–æ—Å–∞ –∏ —á–∞–Ω–∫–∞
   * Threshold: 0.5 –º–∏–Ω–∏–º—É–º

2. **Keyword Match Score** (0.0 - 1.0)
   * BM25 score –æ—Ç PostgreSQL full-text search
   * –í—ã—à–µ –µ—Å–ª–∏ —Ç–æ—á–Ω—ã–µ —Å–ª–æ–≤–∞ —Å–æ–≤–ø–∞–¥–∞—é—Ç

3. **Combined Score** (–¥–ª—è Hybrid)
   ```
   combined = (0.7 √ó vector_score) + (0.3 √ó keyword_score)
   ```

4. **Rerank Score** (0.0 - 1.0)
   * LLM –æ—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
   * **–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞** –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏

### –ü—Ä–∏–º–µ—Ä Scoring

```
Query: "–ö–∞–∫–æ–π —à—Ç—Ä–∞—Ñ –∑–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ 228?"

Chunk 1: "–°—Ç–∞—Ç—å—è 228. –ù–µ–∑–∞–∫–æ–Ω–Ω—ã–π –æ–±–æ—Ä–æ—Ç –Ω–∞—Ä–∫–æ—Ç–∏—á–µ—Å–∫–∏—Ö —Å—Ä–µ–¥—Å—Ç–≤..."
  ‚îú‚îÄ Vector: 0.92 (–≤—ã—Å–æ–∫–∞—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å)
  ‚îú‚îÄ Keyword: 0.95 (—Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ "—Å—Ç–∞—Ç—å—è 228")
  ‚îú‚îÄ Combined: 0.93
  ‚îî‚îÄ Rerank: 0.98 ‚úÖ TOP-1

Chunk 2: "–ó–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ 228 –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω–æ –Ω–∞–∫–∞–∑–∞–Ω–∏–µ..."
  ‚îú‚îÄ Vector: 0.88
  ‚îú‚îÄ Keyword: 0.80
  ‚îú‚îÄ Combined: 0.86
  ‚îî‚îÄ Rerank: 0.95 ‚úÖ TOP-2

Chunk 3: "–°—Ç–∞—Ç—å—è 229 –ø—Ä–µ–¥—É—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç..."
  ‚îú‚îÄ Vector: 0.75 (–ø–æ—Ö–æ–∂–µ, –Ω–æ –¥—Ä—É–≥–∞—è —Å—Ç–∞—Ç—å—è)
  ‚îú‚îÄ Keyword: 0.40
  ‚îú‚îÄ Combined: 0.64
  ‚îî‚îÄ Rerank: 0.30 ‚ùå –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω
```

***

## üìä Flow –î–∏–∞–≥—Ä–∞–º–º—ã

### Flow 1: Smart RAG Search (Full Pipeline)

```mermaid
graph TD
    A[User Query] --> B{Intent Analysis}
    B -->|full_document| C{Check Size}
    C -->|< 400K| D[Load Full Document]
    C -->|> 400K| E[Iterative Batching]
    
    E --> E1[Batch 1: chars 0-20000]
    E1 --> E2[Batch 2: chars 20000-40000]
    E2 --> E3[Batch N: remaining]
    E3 --> E4[Synthesize All Batches]
    
    B -->|single_section| F[Load Chapter]
    B -->|multiple_sections| G[Load Chapters]
    B -->|search| H{Select Strategy}
    
    H -->|specific| I[HyDE + Step-Back]
    H -->|broad| J[Multi-Query]
    H -->|complex| K[Agentic]
    
    I --> L[Get Candidates]
    J --> L
    K --> L
    
    L --> M[Rerank Top-K]
    M --> N[Build Context]
    
    D --> N
    E4 --> N
    F --> N
    G --> N
    
    N --> O{Check Size}
    O -->|too large| P[Adaptive Compression]
    O -->|ok| Q[Final Context]
    P --> Q
    
    Q --> R[Send to LLM]
    R --> S[Response + Sources + Debug]
```

### Flow 2: Iterative Batching (Large Documents)

```mermaid
graph LR
    A[Document: 1M chars] --> B[Split into Batches]
    B --> C[Batch 1: 0-20K]
    B --> D[Batch 2: 20K-40K]
    B --> E[Batch 3: 40K-60K]
    B --> F[...]
    B --> G[Batch N]
    
    C --> C1[LLM: Summarize]
    D --> D1[LLM: Summarize]
    E --> E1[LLM: Summarize]
    G --> G1[LLM: Summarize]
    
    C1 --> H[Summary 1]
    D1 --> I[Summary 2]
    E1 --> J[Summary 3]
    G1 --> K[Summary N]
    
    H --> L[Synthesis Agent]
    I --> L
    J --> L
    K --> L
    
    L --> M[Final Answer]
```

### Flow 3: Agentic Retrieval

```mermaid
graph TD
    A[User Query] --> B[Agent: What to search?]
    B --> C[Search Query 1]
    C --> D[Vector Search]
    D --> E[Results 1]
    
    E --> F[Agent: Enough info?]
    F -->|No| G[Search Query 2]
    F -->|Yes| K[Done]
    
    G --> H[Vector Search]
    H --> I[Results 2]
    
    I --> J[Agent: Enough info?]
    J -->|No| B
    J -->|Yes| K
    
    K --> L[Combine All Results]
    L --> M[Rerank]
    M --> N[Return Top-K]
```

***

## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã

### Global Settings

| Parameter | Default | Description |
|-----------|---------|-------------|
| `CHUNK_SIZE` | 1000 chars | –†–∞–∑–º–µ—Ä –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ |
| `CHUNK_OVERLAP` | 200 chars | Overlap –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏ |
| `EMBEDDING_MODEL` | text-embedding-3-small | OpenAI embedding model |
| `EMBEDDING_DIMENSIONS` | 1536 | –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤ |

### Search Settings

| Parameter | Default | Range | Description |
|-----------|---------|-------|-------------|
| `threshold` | 0.5 | 0.0-1.0 | –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è similarity –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ |
| `vector_weight` | 0.7 | 0.0-1.0 | –í–µ—Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ hybrid |
| `keyword_weight` | 0.3 | 0.0-1.0 | –í–µ—Å keyword –ø–æ–∏—Å–∫–∞ –≤ hybrid |
| `top_k` | 5-10 | 1-50 | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ |
| `candidates` | 20 | 10-100 | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–æ rerank |

### Compression Settings

| Parameter | Default | Description |
|-----------|---------|-------------|
| `max_tokens` | 50,000 | –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ (–¥–æ compression) |
| `target_ratio` | 0.7 | –¶–µ–ª–µ–≤–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç –æ—Ç model context window |
| `safety_buffer` | 5,000 | –¢–æ–∫–µ–Ω—ã –∑–∞–ø–∞—Å –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ |

### Model Context Limits

| Model | Context Window | Effective Limit (70% - 5K) |
|-------|---------------|----------------------------|
| GPT-4o | 128,000 | 84,600 tokens |
| GPT-4 Turbo | 128,000 | 84,600 tokens |
| GPT-3.5 Turbo | 16,000 | 6,200 tokens |
| Claude 3 Opus | 200,000 | 135,000 tokens |
| Claude 3 Sonnet | 200,000 | 135,000 tokens |
| Gemini 1.5 Pro | 1,000,000 | 695,000 tokens |
| DeepSeek V3 | 64,000 | 39,800 tokens |

### Strategy Selection Rules

```python
# Auto-detect strategy based on query
if any(kw in query.lower() for kw in ["—Å—Ç—Ä–∞–Ω–∏—Ü–∞", "—Ü–∏—Ç–∞—Ç", "–∞–±–∑–∞—Ü"]):
    strategy = "hyde"  # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π –ø–æ–∏—Å–∫
    
elif any(kw in query.lower() for kw in ["–æ —á–µ–º", "–æ–±–∑–æ—Ä", "—Ä–µ–∑—é–º–µ"]):
    strategy = "multi_query"  # –®–∏—Ä–æ–∫–∏–π –ø–æ–∏—Å–∫
    
else:
    strategy = "multi_query"  # Default
```

***

## üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### –ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –≤–µ—Å–∞ Hybrid Search

```python
# –í –≤—ã–∑–æ–≤–µ smart_rag_search –∏–ª–∏ build_rag_context
context, sources = rag_store.build_rag_context(
    query=query,
    user_email=user_email,
    use_hybrid=True,
    keyword_weight=0.4,    # –ë–æ–ª—å—à–µ –≤–µ—Å keyword (–¥–ª—è —Ç–æ—á–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤)
    semantic_weight=0.6    # –ú–µ–Ω—å—à–µ –≤–µ—Å semantic
)
```

**–ö–æ–≥–¥–∞ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å keyword\_weight:**

* –ü–æ–∏—Å–∫ –∏–º–µ–Ω, –¥–∞—Ç, —á–∏—Å–µ–ª
* –¢–æ—á–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã (–Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–∞—Ç–µ–π, –∑–∞–∫–æ–Ω–æ–≤)
* –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã

**–ö–æ–≥–¥–∞ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å semantic\_weight:**

* –ö–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
* –°–∏–Ω–æ–Ω–∏–º—ã –∏ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏–µ
* –•—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã

***

### –ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Reranking

```python
# –ò–∑–º–µ–Ω–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
results = rag_store.search_with_rerank(
    query=query,
    user_email=user_email,
    top_k=10,           # –§–∏–Ω–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    use_hybrid=True
)

# –í–Ω—É—Ç—Ä–∏ –º–µ—Ç–æ–¥–∞:
# 1. –ü–æ–ª—É—á–∞–µ—Ç 20 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (top_k * 2)
# 2. Rerank
# 3. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç top 10
```

***

### –ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Adaptive Compression

```python
# –í –∫–æ–¥–µ rag.py, –º–µ—Ç–æ–¥ adaptive_context_compression
def adaptive_context_compression(
    self,
    context: str,
    max_tokens: int,
    model_name: str = "gpt-4o"
):
    # –ü–æ–ª—É—á–∏—Ç—å –ª–∏–º–∏—Ç –º–æ–¥–µ–ª–∏
    model_limits = {
        "gpt-4o": 128000,
        "gpt-4-turbo": 128000,
        "gpt-3.5-turbo": 16000,
        "gemini-1.5-pro": 1000000,
        "claude-3-opus": 200000,
        "deepseek-chat": 64000,
    }
    
    # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –ª–∏–º–∏—Ç: 70% - 5000 —Ç–æ–∫–µ–Ω–æ–≤
    model_limit = model_limits.get(model_name, 128000)
    effective_limit = int(model_limit * 0.7) - 5000  # ‚Üê –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–¥–µ—Å—å
    
    # –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–æ–ª—å—à–µ - –æ–±—Ä–µ–∑–∞—Ç—å
    if estimated_tokens > effective_limit:
        # –û–±—Ä–µ–∑–∞—Ç—å
        ...
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:**

* `0.7` - –ø—Ä–æ—Ü–µ–Ω—Ç –æ—Ç context window (–º–æ–∂–Ω–æ 0.6 –∏–ª–∏ 0.8)
* `5000` - safety buffer –¥–ª—è –æ—Ç–≤–µ—Ç–∞ (–º–æ–∂–Ω–æ 3000-10000)

***

## üìà Performance Metrics

### –¢–∏–ø–∏—á–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

| Operation | Time | Bottleneck |
|-----------|------|------------|
| Intent Analysis | 0.5-1s | OpenAI API call |
| Vector Search | 0.1-0.3s | Database query |
| Hybrid Search | 0.2-0.5s | Database query |
| HyDE Generation | 1-2s | OpenAI API call |
| Multi-Query Generation | 0.5-1s | OpenAI API call |
| Reranking (10 chunks) | 1-2s | OpenAI API call |
| Adaptive Compression | 0.01-0.1s | Text processing |
| **Total (search mode)** | **3-7s** | Multiple API calls |
| **Total (chapter mode)** | **0.5-1s** | Database only |

### Cost Estimates (OpenAI)

| Component | Model | Tokens | Cost per Query |
|-----------|-------|--------|----------------|
| Intent Analysis | gpt-4o-mini | ~500 | $0.00008 |
| HyDE Generation | gpt-4o-mini | ~800 | $0.00012 |
| Multi-Query Gen | gpt-4o-mini | ~300 | $0.00005 |
| Reranking | gpt-4o-mini | ~2000 | $0.0003 |
| Embeddings (query) | text-embedding-3-small | ~100 | $0.000002 |
| **Total per search** | | | **~$0.0005** |

***

## üöÄ Future Improvements

### –ü–ª–∞–Ω–∏—Ä—É–µ–º—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

1. **–í—ã–Ω–µ—Å—Ç–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ UI**
   * Vector/keyword weights
   * Top-K parameters
   * Compression ratios
   * Strategy selection

2. **–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø–æ–ª–Ω—ã–π request**
   * Debug mode –≤ UI
   * –ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤ –º–æ–¥–µ–ª—å
   * –í—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —à–∞–≥–∏

3. **–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ**
   * –ö—ç—à–∏—Ä–æ–≤–∞—Ç—å intent analysis –¥–ª—è –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
   * –ö—ç—à–∏—Ä–æ–≤–∞—Ç—å embeddings —á–∞—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

4. **Streaming Responses**
   * –í–æ–∑–≤—Ä–∞—â–∞—Ç—å —á–∞–Ω–∫–∏ –ø–æ –º–µ—Ä–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
   * –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

5. **Advanced Chunking**
   * Semantic chunking (—Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ —Å–º—ã—Å–ª—É, –Ω–µ –ø–æ —Ä–∞–∑–º–µ—Ä—É)
   * –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ø–∏—Å–∫–∏)

6. **Multi-Document RAG**
   * –ü–æ–∏—Å–∫ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
   * –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤

***

## üìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ Inspiration

–≠—Ç–∞ —Å–∏—Å—Ç–µ–º–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏—Ö —Ç–µ—Ö–Ω–∏–∫–∞—Ö –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö:

1. **HyDE** - [Hypothetical Document Embeddings](https://arxiv.org/abs/2212.10496)
2. **Multi-Query RAG** - Google's Multi-Query approach
3. **Agentic RAG** - Inspired by LangChain Agents
4. **Step-Back Prompting** - Google DeepMind research
5. **Hybrid Search** - BM25 + Dense retrieval (standard)
6. **Reranking** - LLM-based reranking for better precision

***

## üéì –ì–ª–æ—Å—Å–∞—Ä–∏–π

| –¢–µ—Ä–º–∏–Ω | –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ |
|--------|-------------|
| **Chunk** | –§—Ä–∞–≥–º–µ–Ω—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–æ–±—ã—á–Ω–æ 1000 —Å–∏–º–≤–æ–ª–æ–≤) |
| **Embedding** | –í–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ (1536 —á–∏—Å–µ–ª) |
| **Vector Search** | –ü–æ–∏—Å–∫ –ø–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –±–ª–∏–∑–æ—Å—Ç–∏ –≤–µ–∫—Ç–æ—Ä–æ–≤ |
| **Hybrid Search** | –ö–æ–º–±–∏–Ω–∞—Ü–∏—è keyword + vector –ø–æ–∏—Å–∫–∞ |
| **Reranking** | –ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ LLM'–æ–º |
| **HyDE** | –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç |
| **Top-K** | K –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ |
| **Similarity** | –ú–µ—Ä–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ (0.0 - 1.0) |
| **Context Window** | –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –º–æ–¥–µ–ª–∏ |
| **Compression** | –°–∂–∞—Ç–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–¥ –ª–∏–º–∏—Ç –º–æ–¥–µ–ª–∏ |

***

## üìû –ö–æ–Ω—Ç–∞–∫—Ç—ã –∏ –ü–æ–¥–¥–µ—Ä–∂–∫–∞

**–ê–≤—Ç–æ—Ä:** Amirkhan\
**–ü—Ä–æ–µ–∫—Ç:** MultiProvider RAG System\
**GitHub:** https://github.com/Amo808/multiprovider

**–î–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤:**

* –°–æ–∑–¥–∞–π—Ç–µ Issue –Ω–∞ GitHub
* –ò–ª–∏ —Å–º–æ—Ç—Ä–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –≤ `/docs/`

***

**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** January 8, 2026\
**–í–µ—Ä—Å–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:** 1.0.0
